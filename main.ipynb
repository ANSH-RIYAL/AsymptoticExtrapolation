{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import tanh, sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions:\n",
    "\n",
    "def targetValueFunction(inpAttr, iteration):\n",
    "#     inpAttr shape = (samples, numberOfAttributes)\n",
    "    bias = np.random.random_sample(inpAttr.shape[1])\n",
    "    bias = (0.6-0.2)*bias + 0.2\n",
    "#     Setting range of random bias as 0.2 to 0.6\n",
    "#     Will add the same bias to all samples\n",
    "#     print(bias)\n",
    "    target = calculate(inpAttr, bias)\n",
    "    bias = np.random.random_sample(inpAttr.shape[1])\n",
    "    bias = (0.6-0.2)*bias + 0.2\n",
    "    t = cFunc1(inpAttr, bias)\n",
    "    t = np.expand_dims(t, axis=1)\n",
    "    t1 = np.concatenate((inpAttr,t), axis = 1)\n",
    "    print(t1.shape)\n",
    "    print(t1)\n",
    "    with open('./data/function1_{}_values.npy'.format(iteration), 'wb') as f:\n",
    "        np.save(f, np.asarray(t1))\n",
    "    \n",
    "    bias = np.random.random_sample(inpAttr.shape[1])\n",
    "    bias = (0.6-0.2)*bias + 0.2\n",
    "    t = cFunc2(inpAttr, bias)\n",
    "    t = np.expand_dims(t, axis=1)\n",
    "    t2 = np.concatenate((inpAttr,t), axis = 1)\n",
    "    with open('./data/function2_{}_values.npy'.format(iteration), 'wb') as f:\n",
    "        np.save(f, np.asarray(t2))\n",
    "    \n",
    "    bias = np.random.random_sample(inpAttr.shape[1])\n",
    "    bias = (0.6-0.2)*bias + 0.2\n",
    "    t = cFunc3(inpAttr, bias)\n",
    "    t = np.expand_dims(t, axis=1)\n",
    "    t3 = np.concatenate((inpAttr,t), axis = 1)\n",
    "    with open('./data/function3_{}_values.npy'.format(iteration), 'wb') as f:\n",
    "        np.save(f, np.asarray(t3))\n",
    "    \n",
    "    bias = np.random.random_sample(inpAttr.shape[1])\n",
    "    bias = (0.6-0.2)*bias + 0.2\n",
    "    t = cFunc4(inpAttr, bias)\n",
    "    t = np.expand_dims(t, axis=1)\n",
    "    t4 = np.concatenate((inpAttr,t), axis = 1)\n",
    "    with open('./data/function4_{}_values.npy'.format(iteration), 'wb') as f:\n",
    "        np.save(f, np.asarray(t4))\n",
    "    \n",
    "    bias = np.random.random_sample(inpAttr.shape[1])\n",
    "    bias = (0.6-0.2)*bias + 0.2\n",
    "    t = cFunc5(inpAttr, bias)\n",
    "    t = np.expand_dims(t, axis=1)\n",
    "    t5 = np.concatenate((inpAttr,t), axis = 1)\n",
    "    with open('./data/function5_{}_values.npy'.format(iteration), 'wb') as f:\n",
    "        np.save(f, np.asarray(t5))\n",
    "\n",
    "#     print(target)\n",
    "    return target\n",
    "\n",
    "def calculate(inpAttr, bias):\n",
    "    inpAttr = inpAttr*inpAttr\n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        for j in range(inpAttr.shape[1]):\n",
    "            inpAttr[i][j] = tanh(inpAttr[i][j])\n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        inpAttr[i] += bias\n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        for j in range(inpAttr.shape[1]):\n",
    "            inpAttr[i][j] = sqrt(inpAttr[i][j])\n",
    "#     returns values = sum(root(tanh(x^2) + bias))\n",
    "    target = np.sum(inpAttr, axis = 1)\n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cFunc1(inpAttr, bias):\n",
    "    inpAttr = inpAttr*inpAttr*inpAttr*inpAttr\n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        for j in range(inpAttr.shape[1]):\n",
    "            inpAttr[i][j] = tanh(inpAttr[i][j])\n",
    "    \n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        for j in range(inpAttr.shape[1]):\n",
    "            inpAttr[i][j] = sqrt(inpAttr[i][j])\n",
    "    \n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        inpAttr[i] += bias\n",
    "#     returns values = sum(root(tanh(x^4)) + bias)\n",
    "    target = np.sum(inpAttr, axis = 1)\n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cFunc2(inpAttr, bias):\n",
    "    inpAttr = inpAttr*inpAttr\n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        for j in range(inpAttr.shape[1]):\n",
    "            inpAttr[i][j] = tanh(inpAttr[i][j])\n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        inpAttr[i] += bias\n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        for j in range(inpAttr.shape[1]):\n",
    "            inpAttr[i][j] = sqrt(inpAttr[i][j])\n",
    "#     returns values = sum(root(tanh(x^2) + bias))\n",
    "    target = np.sum(inpAttr, axis = 1)\n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cFunc3(inpAttr, bias):\n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        for j in range(inpAttr.shape[1]):\n",
    "            inpAttr[i][j] = tanh(inpAttr[i][j])\n",
    "            inpAttr[i][j] *= inpAttr[i][j]\n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        inpAttr[i] += bias\n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        for j in range(inpAttr.shape[1]):\n",
    "            inpAttr[i][j] = sqrt(inpAttr[i][j])\n",
    "#     returns values = sum(root(tanh(x)^2 + bias))\n",
    "    target = np.sum(inpAttr, axis = 1)\n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cFunc4(inpAttr, bias):\n",
    "    inpAttr = inpAttr*inpAttr\n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        for j in range(inpAttr.shape[1]):\n",
    "            inpAttr[i][j] = tanh(inpAttr[i][j])\n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        inpAttr[i] += bias\n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        for j in range(inpAttr.shape[1]):\n",
    "            inpAttr[i][j] = sqrt(inpAttr[i][j])\n",
    "#     returns values = sum(root(tanh(x^2) + bias))\n",
    "    target = np.sum(inpAttr, axis = 1)\n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cFunc5(inpAttr, bias):\n",
    "    inpAttr = inpAttr*inpAttr\n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        for j in range(inpAttr.shape[1]):\n",
    "            inpAttr[i][j] = tanh(inpAttr[i][j])\n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        inpAttr[i] += bias\n",
    "    for i in range(inpAttr.shape[0]):\n",
    "        for j in range(inpAttr.shape[1]):\n",
    "            inpAttr[i][j] = sqrt(inpAttr[i][j])\n",
    "#     returns values = sum(root(tanh(x^2) + bias))\n",
    "    target = np.sum(inpAttr, axis = 1)\n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted Scenes till here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   2.   3.   4. ]\n",
      " [ 3.   1.   3.   5. ]\n",
      " [ 1.  -2.   0.3  2.5]]\n",
      "[[ 0.1   0.2   0.3   0.4 ]\n",
      " [ 0.3   0.1   0.3   0.5 ]\n",
      " [ 0.1  -0.2   0.03  0.25]]\n"
     ]
    }
   ],
   "source": [
    "trial = []\n",
    "trial.append([1,2,3,4])\n",
    "trial.append([3,1,3,5])\n",
    "trial.append([1,-2,0.3,2.5])\n",
    "trial = np.asarray(trial)\n",
    "print(trial)\n",
    "trial = trial/10\n",
    "print(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "print(trial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1 ,  0.2 ,  0.3 ,  0.4 ],\n",
       "       [ 0.3 ,  0.1 ,  0.3 ,  0.5 ],\n",
       "       [ 0.1 , -0.2 ,  0.03,  0.25]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n",
      "[[ 0.1         0.2         0.3         0.4         2.0841275 ]\n",
      " [ 0.3         0.1         0.3         0.5         2.22398144]\n",
      " [ 0.1        -0.2         0.03        0.25        1.89754579]]\n"
     ]
    }
   ],
   "source": [
    "t = targetValueFunction(trial,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46116978, 0.73900515, 0.75507616, 0.7499539 ],\n",
       "       [0.53628993, 0.71910034, 0.75507616, 0.79474644],\n",
       "       [0.46116978, 0.73900515, 0.69726353, 0.69141506]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some adjustable parameters (hyper parameters in our case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 11)\n",
      "[[5.70310346e-01 3.74155842e-01 9.95362294e-01 ... 6.48974452e-02\n",
      "  7.96875187e-01 7.39955789e+00]\n",
      " [2.45848045e-01 6.22912181e-01 2.72847537e-01 ... 6.99264974e-01\n",
      "  8.79687959e-01 7.04804544e+00]\n",
      " [8.97072368e-01 2.55971638e-01 8.40697302e-01 ... 6.57982157e-01\n",
      "  5.29337450e-01 6.91496966e+00]\n",
      " ...\n",
      " [6.41525255e-03 2.58696196e-01 4.72927244e-01 ... 8.79985982e-01\n",
      "  9.95684142e-01 7.40725152e+00]\n",
      " [1.97976991e-01 8.21878655e-01 5.57168814e-01 ... 7.31400954e-01\n",
      "  7.56497847e-01 7.20906397e+00]\n",
      " [2.65957979e-01 4.28446538e-01 8.42783360e-01 ... 3.38727539e-01\n",
      "  7.99299131e-01 5.93228807e+00]]\n",
      "8.185491990742305\n",
      "(50000, 11)\n",
      "[[0.59931191 0.92200597 0.01784142 ... 0.58632547 0.26969576 7.08258991]\n",
      " [0.06633257 0.28298197 0.89539006 ... 0.05074538 0.53221867 7.59655123]\n",
      " [0.96263681 0.18538775 0.667242   ... 0.86805701 0.68891199 8.14121089]\n",
      " ...\n",
      " [0.69610688 0.02124593 0.12198202 ... 0.57984113 0.237929   6.8153366 ]\n",
      " [0.66879263 0.62506918 0.87682436 ... 0.64390316 0.45004403 7.787658  ]\n",
      " [0.28755578 0.6215305  0.42206826 ... 0.74891566 0.37078752 7.17471764]]\n",
      "7.698727134783774\n",
      "(50000, 11)\n",
      "[[0.3309867  0.30674398 0.85162322 ... 0.43836314 0.65623354 8.00504464]\n",
      " [0.13463605 0.46022203 0.18383414 ... 0.82622357 0.3821806  6.51405896]\n",
      " [0.14662271 0.62707652 0.16967131 ... 0.42426392 0.86348711 6.97787917]\n",
      " ...\n",
      " [0.92194071 0.8825558  0.66835473 ... 0.92207138 0.21498178 8.32029684]\n",
      " [0.81528682 0.05337003 0.15995869 ... 0.89353032 0.95235589 6.97369803]\n",
      " [0.4651944  0.52036931 0.75502897 ... 0.79448913 0.61289092 7.68887451]]\n",
      "8.836659164143947\n",
      "(50000, 11)\n",
      "[[0.27946933 0.02969591 0.89573306 ... 0.45662078 0.9117574  7.43862679]\n",
      " [0.36091244 0.2688298  0.43628438 ... 0.8428435  0.8798258  8.82116116]\n",
      " [0.14467101 0.51487486 0.26733331 ... 0.58549573 0.51436065 6.82721205]\n",
      " ...\n",
      " [0.87784121 0.11316888 0.36324468 ... 0.01194372 0.7142941  7.26077291]\n",
      " [0.14823387 0.13168134 0.19499132 ... 0.52995193 0.90484399 7.50537056]\n",
      " [0.59546347 0.30221025 0.47413357 ... 0.73922347 0.33670642 7.30852219]]\n",
      "8.19281587229642\n",
      "(50000, 11)\n",
      "[[0.72584123 0.98345444 0.76616856 ... 0.74619505 0.07304688 7.9486547 ]\n",
      " [0.50139679 0.91558108 0.16545673 ... 0.4722214  0.21805538 7.27735797]\n",
      " [0.06676073 0.63187164 0.02160136 ... 0.09808968 0.59386373 6.16068128]\n",
      " ...\n",
      " [0.880808   0.51801872 0.76998148 ... 0.47159221 0.39163218 6.32904804]\n",
      " [0.58325994 0.71709211 0.72601282 ... 0.50712041 0.43500303 6.92290471]\n",
      " [0.02684329 0.52350945 0.55930815 ... 0.31029318 0.08527759 6.22172477]]\n",
      "8.752897103724965\n",
      "(50000, 11)\n",
      "[[0.25312809 0.15403171 0.64502955 ... 0.98984994 0.25010407 6.19632436]\n",
      " [0.17219086 0.2846055  0.11674789 ... 0.36455237 0.37470847 5.1578105 ]\n",
      " [0.26292746 0.92561746 0.66369928 ... 0.45228887 0.51202258 7.66012698]\n",
      " ...\n",
      " [0.34350647 0.14930383 0.91776238 ... 0.7937803  0.72286718 7.91526632]\n",
      " [0.63200649 0.1368644  0.56591482 ... 0.44321353 0.83319075 5.92666351]\n",
      " [0.75138312 0.24638005 0.7547336  ... 0.5814192  0.3763374  6.38249261]]\n",
      "7.466797400127315\n",
      "(50000, 11)\n",
      "[[0.60044891 0.0570505  0.09745196 ... 0.58521041 0.90504684 6.67328633]\n",
      " [0.18733327 0.96403958 0.55357376 ... 0.83665518 0.35736374 7.46334102]\n",
      " [0.18061738 0.75736227 0.69745774 ... 0.20028637 0.51217271 7.04522472]\n",
      " ...\n",
      " [0.49749867 0.03159228 0.03048372 ... 0.99969608 0.29663605 7.4005756 ]\n",
      " [0.78029919 0.08657528 0.75988705 ... 0.80469109 0.68377737 7.73753884]\n",
      " [0.15816416 0.20771907 0.37734539 ... 0.02081376 0.57127778 5.45095274]]\n",
      "8.140020033448637\n",
      "(50000, 11)\n",
      "[[0.11866858 0.15952036 0.01697073 ... 0.65529857 0.55953271 6.12730865]\n",
      " [0.07699615 0.83540304 0.19779081 ... 0.22735793 0.27660974 6.44120601]\n",
      " [0.5040091  0.16490154 0.23758478 ... 0.01461174 0.50597088 6.24934486]\n",
      " ...\n",
      " [0.66036043 0.06648107 0.85747587 ... 0.40428959 0.53028813 7.09664994]\n",
      " [0.66200259 0.188362   0.8793018  ... 0.02270046 0.93040283 7.3507256 ]\n",
      " [0.43406537 0.39315314 0.06660287 ... 0.32572364 0.81317274 6.58823764]]\n",
      "7.004267749789944\n",
      "(50000, 11)\n",
      "[[0.18140859 0.23217887 0.44865826 ... 0.22796007 0.9481889  6.90780435]\n",
      " [0.70870838 0.88071373 0.752979   ... 0.52919505 0.60599811 7.8804069 ]\n",
      " [0.85251787 0.8183438  0.11802178 ... 0.70303883 0.53829705 7.41805236]\n",
      " ...\n",
      " [0.42565995 0.66378754 0.24609186 ... 0.26374294 0.95396733 7.50806564]\n",
      " [0.27278797 0.74766922 0.79149194 ... 0.14360151 0.60287608 6.58859506]\n",
      " [0.38936634 0.52583778 0.58621334 ... 0.27477259 0.65915853 6.71070189]]\n",
      "7.954637685597865\n",
      "(50000, 11)\n",
      "[[0.06686643 0.68432841 0.69073234 ... 0.87204448 0.97636695 8.42745636]\n",
      " [0.07988187 0.6347491  0.67517413 ... 0.6747904  0.90479622 7.75605075]\n",
      " [0.13030568 0.26113966 0.41829469 ... 0.99842419 0.56292012 6.68022965]\n",
      " ...\n",
      " [0.81774408 0.30798    0.9642067  ... 0.46073253 0.87022345 7.53113687]\n",
      " [0.67043256 0.2842805  0.49926264 ... 0.2444565  0.51683172 7.54630554]\n",
      " [0.35824087 0.94260624 0.74032834 ... 0.01140893 0.95673319 6.82949501]]\n",
      "9.235758035769313\n"
     ]
    }
   ],
   "source": [
    "numSamples = 50000\n",
    "numAttributes = 10\n",
    "for i in range(10):\n",
    "    inpX = np.random.random_sample((numSamples,numAttributes))\n",
    "    targets = targetValueFunction(inpX,i)\n",
    "    print(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(inpX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "(2, 3)\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "[[  1   2   3 100]\n",
      " [  4   5   6 100]]\n"
     ]
    }
   ],
   "source": [
    "a = np.asarray([[1,2,3],[4,5,6]])\n",
    "b = np.asarray([[7,8,9],[10,11,12]])\n",
    "d = np.asarray([[100],[100]])\n",
    "print(d.shape)\n",
    "print(a.shape)\n",
    "c = np.concatenate((a,b))\n",
    "print(c)\n",
    "e = np.concatenate((a,d), axis = 1)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29355 0\n",
      "29355 1\n",
      "(50000, 11)\n",
      "(50000, 11)\n",
      "29355 2\n",
      "(100000, 11)\n",
      "(50000, 11)\n",
      "29355 3\n",
      "(150000, 11)\n",
      "(50000, 11)\n",
      "29355 4\n",
      "(200000, 11)\n",
      "(50000, 11)\n",
      "29355 5\n",
      "(250000, 11)\n",
      "(50000, 11)\n",
      "29355 6\n",
      "(300000, 11)\n",
      "(50000, 11)\n",
      "29355 7\n",
      "(350000, 11)\n",
      "(50000, 11)\n",
      "29355 8\n",
      "(400000, 11)\n",
      "(50000, 11)\n",
      "29355 9\n",
      "(450000, 11)\n",
      "(50000, 11)\n",
      "(500000, 11)\n"
     ]
    }
   ],
   "source": [
    "allValues = None\n",
    "# for i in range(1,6):\n",
    "#     for j in range(10):\n",
    "#         print(i,j)\n",
    "#         targets = np.load(\"./data/function{}_{}_values.npy\".format(i,j))\n",
    "#         if type(allValues) == type(None):\n",
    "#             allValues = np.array(targets)\n",
    "#         else:\n",
    "#             print(allValues.shape)\n",
    "#             print(targets.shape)\n",
    "#             allValues = np.concatenate((allValues,targets))\n",
    "\n",
    "for j in range(10):\n",
    "    print(i,j)\n",
    "    targets = np.load(\"./data/function{}_{}_values.npy\".format(1,j))\n",
    "    if type(allValues) == type(None):\n",
    "        allValues = np.array(targets)\n",
    "    else:\n",
    "        print(allValues.shape)\n",
    "        print(targets.shape)\n",
    "        allValues = np.concatenate((allValues,targets))\n",
    "\n",
    "print(allValues.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted Scenes Till Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 441\n",
      "Trainable params: 441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Neural Network which must not be named..... jk, who's working has to be optimised\n",
    "def createExpModel():\n",
    "    experimentalModel = Sequential()\n",
    "    experimentalModel.add(Dense(2*numAttributes, input_shape = (numAttributes,), activation = tf.keras.activations.tanh))\n",
    "    experimentalModel.add(Dense(numAttributes))\n",
    "    experimentalModel.add(Dense(1))\n",
    "    experimentalModel.summary()\n",
    "    return experimentalModel\n",
    "\n",
    "experimentalModel = createExpModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.04889905, -0.4302321 , -0.36297965, -0.01815006, -0.42767432,\n",
       "          0.42139095, -0.41733435,  0.44712842,  0.3098926 ,  0.09827942,\n",
       "          0.31439835,  0.3858539 , -0.1769543 , -0.2272591 ,  0.112795  ,\n",
       "         -0.18547729,  0.01060194, -0.20006634, -0.26671648, -0.4347791 ],\n",
       "        [-0.14179662, -0.36507118, -0.3573197 ,  0.15212208, -0.24549629,\n",
       "         -0.13250327, -0.15406576, -0.35363138,  0.4395355 ,  0.3902157 ,\n",
       "          0.19842935,  0.34412456,  0.25056934,  0.08811945, -0.41876352,\n",
       "         -0.24306238, -0.16111553, -0.39708346,  0.42629778,  0.43122298],\n",
       "        [-0.22630513,  0.05874878,  0.13124853,  0.4321651 , -0.16952047,\n",
       "          0.2773143 , -0.28000206, -0.14868146, -0.3887347 , -0.4442198 ,\n",
       "          0.38159245,  0.00304827, -0.36095762,  0.2758485 ,  0.42703938,\n",
       "         -0.10204217,  0.1244759 , -0.39547375, -0.4216847 ,  0.42142922],\n",
       "        [ 0.27924973, -0.22414845, -0.09534961,  0.4467966 , -0.03868023,\n",
       "          0.36248428,  0.04637462, -0.13205728, -0.23932116,  0.18329728,\n",
       "         -0.21454674, -0.39596155, -0.40385833,  0.02491558, -0.4199493 ,\n",
       "          0.40019125,  0.42987943,  0.09459245, -0.37225872, -0.05245242],\n",
       "        [ 0.18594229, -0.06372482,  0.15742803,  0.2533052 , -0.08789977,\n",
       "         -0.40565187, -0.10612088, -0.413345  ,  0.3932143 , -0.2050909 ,\n",
       "         -0.02719274, -0.02713934, -0.09802863, -0.318277  , -0.4436436 ,\n",
       "          0.33766252, -0.00754452, -0.12904641,  0.15384662,  0.08775318],\n",
       "        [-0.32389128,  0.02029118,  0.19842231,  0.02233315, -0.16572744,\n",
       "         -0.2833448 ,  0.21744424,  0.21100736, -0.40609   , -0.26170206,\n",
       "         -0.28784722,  0.30609423, -0.24340837,  0.14092904, -0.3659343 ,\n",
       "          0.36353558, -0.14599827, -0.03588113, -0.22835018, -0.3124179 ],\n",
       "        [-0.25767273,  0.33927464,  0.08572382, -0.2939186 , -0.4064039 ,\n",
       "          0.42301828,  0.03431109, -0.3530572 , -0.0124698 ,  0.02020001,\n",
       "          0.03751695, -0.05159569, -0.17013207, -0.30536643,  0.42468566,\n",
       "         -0.145392  , -0.29177678,  0.26725036, -0.3684775 , -0.34692153],\n",
       "        [ 0.3420809 , -0.29162163, -0.120462  ,  0.07586652,  0.05951452,\n",
       "          0.04877687, -0.26565793, -0.3501643 , -0.3346542 ,  0.08685243,\n",
       "          0.15249062,  0.19015497, -0.401126  , -0.28247756,  0.17089754,\n",
       "          0.12938035, -0.2767899 ,  0.33139038,  0.25254947,  0.21131486],\n",
       "        [-0.36567745, -0.2939231 ,  0.37557715,  0.28072423,  0.07743889,\n",
       "         -0.11281493, -0.27651632, -0.15303874,  0.330467  ,  0.26157647,\n",
       "         -0.2684629 , -0.04781735, -0.35961288, -0.3978681 , -0.17578197,\n",
       "          0.00959307, -0.43588725,  0.27649647, -0.35451967, -0.10155064],\n",
       "        [-0.41651824,  0.4176222 , -0.2153541 ,  0.08740395,  0.00579396,\n",
       "          0.12553489, -0.03252321, -0.10065895, -0.2535839 , -0.26015666,\n",
       "          0.12979609, -0.07028079, -0.1797275 , -0.08857578,  0.01631498,\n",
       "          0.40270424,  0.07794034, -0.42520425, -0.40964204, -0.341215  ]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.], dtype=float32),\n",
       " array([[-0.4419179 ,  0.29683584,  0.2809021 ,  0.3911636 ,  0.26914978,\n",
       "          0.14026582,  0.32011008, -0.39951852, -0.17117572, -0.2123861 ],\n",
       "        [ 0.2746538 ,  0.42006254,  0.25319207,  0.24684793, -0.29859003,\n",
       "         -0.0516246 , -0.26106212,  0.39515823,  0.01385504, -0.21735148],\n",
       "        [-0.05716348, -0.09487695,  0.25507474, -0.34200042, -0.3688138 ,\n",
       "          0.00978926,  0.15467286, -0.41783333,  0.2552911 , -0.0056982 ],\n",
       "        [ 0.29333997,  0.1528976 ,  0.26178193, -0.4189611 , -0.4279415 ,\n",
       "         -0.08551109,  0.10005426, -0.07534757,  0.10195786,  0.26086783],\n",
       "        [-0.19947788, -0.3087902 , -0.43990794, -0.30300555, -0.18962699,\n",
       "         -0.2306604 ,  0.2410922 , -0.0126487 ,  0.24219394,  0.40809238],\n",
       "        [ 0.26588762,  0.08885163,  0.22009706,  0.09374851,  0.4053095 ,\n",
       "          0.3280058 ,  0.18589526,  0.2653212 , -0.3329376 ,  0.1996178 ],\n",
       "        [ 0.33207178, -0.36317444,  0.00830665,  0.14424622,  0.14104271,\n",
       "          0.40588135, -0.286049  , -0.16132334,  0.22554779,  0.15652269],\n",
       "        [ 0.14582139,  0.23180598,  0.14443332, -0.33247963, -0.2457797 ,\n",
       "          0.09738463, -0.38217294,  0.14974576,  0.09789056,  0.35315192],\n",
       "        [ 0.16323167,  0.40199858,  0.3537249 ,  0.3643648 ,  0.3020633 ,\n",
       "         -0.2576838 , -0.18947291, -0.19308096, -0.04971752, -0.24751052],\n",
       "        [ 0.43033713,  0.07984638, -0.23088431, -0.383241  , -0.23795882,\n",
       "          0.01634151,  0.34566766,  0.25820863, -0.30386484,  0.26220107],\n",
       "        [-0.04651037,  0.33397692, -0.26323807, -0.3713314 , -0.13560072,\n",
       "         -0.23205206, -0.14337093, -0.05642566,  0.37609762, -0.2560492 ],\n",
       "        [-0.22737883,  0.11398804, -0.38075656, -0.15264454, -0.22230758,\n",
       "         -0.4179535 , -0.3363248 , -0.28178182, -0.20210436,  0.39629602],\n",
       "        [ 0.30418217,  0.15130442,  0.34993005,  0.42206484, -0.40169472,\n",
       "         -0.42183313,  0.06435066, -0.26737222, -0.32690522, -0.11551541],\n",
       "        [-0.04048333, -0.2703852 , -0.22394724, -0.04442906, -0.36082307,\n",
       "         -0.40076175, -0.06543294,  0.22731519, -0.36224064, -0.1804454 ],\n",
       "        [-0.23183444,  0.01434466, -0.40534937,  0.2276457 , -0.3555054 ,\n",
       "         -0.37079445, -0.35223782,  0.08065969, -0.09222275, -0.31828403],\n",
       "        [-0.18456426, -0.4086449 ,  0.35927266,  0.05047965,  0.20468605,\n",
       "          0.16902757,  0.38734227,  0.01381016,  0.2582    , -0.15258774],\n",
       "        [-0.23632662, -0.03099263, -0.16294476,  0.18995762,  0.34187138,\n",
       "         -0.13662183,  0.07217669,  0.31091172,  0.34469193, -0.05654815],\n",
       "        [ 0.04744002, -0.2649155 , -0.41955605, -0.16502255,  0.19509202,\n",
       "          0.29645807,  0.3450728 ,  0.09341288, -0.40143722,  0.16903597],\n",
       "        [ 0.35190034,  0.09780335,  0.02915996, -0.31607145, -0.08542237,\n",
       "         -0.40461218,  0.32517087,  0.22068936, -0.11752483,  0.02328914],\n",
       "        [ 0.05660063,  0.23152578,  0.38880503, -0.10171986,  0.03089824,\n",
       "          0.01459768, -0.2502113 , -0.3410347 , -0.27530548,  0.44081253]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.40099245],\n",
       "        [-0.05514753],\n",
       "        [-0.07258189],\n",
       "        [ 0.05020446],\n",
       "        [-0.54911643],\n",
       "        [ 0.26224214],\n",
       "        [ 0.4367996 ],\n",
       "        [-0.6464018 ],\n",
       "        [-0.4048515 ],\n",
       "        [-0.4741822 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experimentalModel.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentalModel.compile(optimizer = 'adam', loss= 'mse', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 11)\n"
     ]
    }
   ],
   "source": [
    "print(allValues.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 10)\n",
      "(500000,)\n"
     ]
    }
   ],
   "source": [
    "inputValues = allValues[:,:10]\n",
    "print(inputValues.shape)\n",
    "targetValues = allValues[:,10]\n",
    "print(targetValues.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 59.7425 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 56.3540 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 61.2605 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 56.2551 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 53.9601 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 58.4090 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 54.3449 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 51.2855 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 56.4509 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 56.2140 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 59.1803 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 55.1785 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48.0848 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 46.2309 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 52.0106 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 50.5173 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48.3956 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 44.5376 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 41.9887 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 44.3699 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 41.2199 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 45.3911 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 50.4942 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 45.7611 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 47.1393 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 40.4872 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 39.2922 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 39.3538 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 39.2505 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 38.6972 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 39.1275 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 43.6652 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 39.0661 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.9904 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 38.4190 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 32.5239 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 33.4654 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 34.0111 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 34.6621 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.6122 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 33.6996 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 33.6818 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.4449 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.7005 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 34.2267 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 29.0289 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 30.7170 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 29.9158 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.6862 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 29.5233 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.7713 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.6263 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 28.4718 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.2884 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 23.9261 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.1333 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 25.8138 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 24.2217 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 23.4913 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 21.4005 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 21.8097 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.9050 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.4485 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.3649 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.2953 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.1836 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 18.7512 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 18.3482 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.1139 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.7815 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.7790 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.0363 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.2818 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.7059 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.3640 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.1269 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 12.5795 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.3608 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.1011 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.9557 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.3979 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.2855 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.4748 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.1691 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.7091 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.3112 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.2953 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.5549 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9574 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.7302 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.5822 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 6.1654 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2089 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1931 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.2924 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4805 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.6674 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3719 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.9770 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.6984 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 999us/step - loss: 4.4144 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.1605 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9146 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5985 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.8626 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1115 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3734 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 988us/step - loss: 2.3301 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.1124 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9833 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7381 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5169 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.9308 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 951us/step - loss: 1.6784 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0693 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9207 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9428 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8364 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8577 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 977us/step - loss: 0.6195 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5508 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5071 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3966 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 944us/step - loss: 0.5204 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3238 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4042 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3024 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3018 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3339 - accuracy: 0.0000e+ - 0s 1ms/step - loss: 0.3339 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1349 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3021 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2875 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 911us/step - loss: 0.1875 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1427 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2755 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.1568 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2361 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2089 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3125 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1268 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1548 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1020 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1275 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2014 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1394 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2620 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2014 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1575 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2623 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0969 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1608 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2129 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2560 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2046 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2515 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2777 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1143 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1381 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1554 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1293 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1109 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1662 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1325 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2609 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1452 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2777 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2247 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1135 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2286 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1644 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1597 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2210 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1453 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0997 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1572 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1425 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1736 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0858 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1398 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1493 - accuracy: 0.0000e+ - 0s 1ms/step - loss: 0.1493 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1683 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2185 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2173 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1597 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1575 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2638 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2031 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2664 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1721 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2518 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1334 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1682 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1719 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2011 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1629 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2302 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1412 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1559 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2653 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0813 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1126 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1674 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1882 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1595 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1470 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1450 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2664 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1093 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2094 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2354 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1534 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1118 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1218 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1306 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1485 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1581 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2508 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2693 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1522 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1245 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1697 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1529 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1318 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1600 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0973 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 985us/step - loss: 0.1811 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2091 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0832 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1447 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1746 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0927 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1072 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1473 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1550 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1688 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1342 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1682 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2729 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0971 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0717 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2129 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2389 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1116 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2536 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2016 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1674 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0881 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2091 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1645 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1631 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1273 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1579 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0834 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0886 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1477 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1412 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1502 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1541 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0916 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0943 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 944us/step - loss: 0.1528 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1517 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2325 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1648 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1345 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1469 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1495 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1427 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0962 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1531 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0820 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1501 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1443 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0821 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1302 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0923 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1644 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1677 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1258 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1610 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0998 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1071 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0963 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0644 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0835 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1417 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1341 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1682 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2123 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1383 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0863 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1609 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2125 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1700 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1345 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1457 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0707 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1460 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0971 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2078 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1649 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1177 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0568 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1466 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0705 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1246 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0835 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 987us/step - loss: 0.2088 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1692 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1291 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1683 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1171 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1224 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2670 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2047 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 966us/step - loss: 0.1464 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0651 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0949 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1437 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1665 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0827 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0651 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1984 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2548 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1727 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1632 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0692 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0663 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0693 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1635 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1110 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1392 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0955 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1423 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2068 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2568 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1423 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1267 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1497 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1467 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0777 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0623 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1374 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1125 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1301 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0847 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0843 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1204 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 972us/step - loss: 0.0965 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1098 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0720 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1311 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2034 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1470 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0803 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2233 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2283 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1332 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1430 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0621 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1128 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0623 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0652 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1173 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 917us/step - loss: 0.1208 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1734 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1447 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0638 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2333 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1045 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2328 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1144 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1062 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0832 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0832 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1571 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1257 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0792 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1271 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1143 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1682 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1150 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0666 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0905 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1610 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1211 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1110 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0504 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0740 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 989us/step - loss: 0.1395 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1549 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0664 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0857 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0948 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1601 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2747 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1200 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1417 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0963 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1175 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1472 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0542 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0790 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0902 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0810 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0810 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1426 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1142 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1092 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1033 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0805 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0876 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0571 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0825 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1382 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1358 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0679 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1238 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2530 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1522 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0739 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1982 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2008 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1610 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0757 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0958 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0777 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0769 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 992us/step - loss: 0.1036 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1373 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1458 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1417 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1710 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1496 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0982 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1378 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0876 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0950 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1003 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0713 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0413 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0617 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0987 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0680 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1347 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1067 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1129 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0849 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0823 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1468 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0666 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0895 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1177 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0864 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0969 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1451 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1489 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0443 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0861 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0640 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1340 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1473 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1052 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1379 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1265 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2083 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0925 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1464 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1718 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0985 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0942 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0836 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1026 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1148 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0759 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0733 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0788 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0944 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0740 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1550 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2111 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1438 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0814 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0736 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0786 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1233 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1548 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1284 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1235 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0657 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1650 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0738 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0650 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0646 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0636 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1462 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1416 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1177 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "trackingArray = []\n",
    "batch_size = 20\n",
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0,inputValues.shape[0]-5,15):\n",
    "        experimentalModel.fit(np.asarray(inputValues[i:i+batch_size]),np.asarray(targetValues[i:i+batch_size]))\n",
    "        trackingArray.append(np.array(experimentalModel.get_weights()))\n",
    "print(len(trackingArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gonna have to figure this part out eh ehe ehehehehe\n",
    "\n",
    "# # list all data in history\n",
    "# print(history.history.keys())\n",
    "# # summarize history for accuracy\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "# # summarize history for loss\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackingArray = np.asarray(trackingArray)\n",
    "trackingArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    print(np.asarray(trackingArray[0][i]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = []\n",
    "layer2 = []\n",
    "for i in range(10*20):\n",
    "    layer1.append([])\n",
    "    layer2.append([])\n",
    "bias1 = []\n",
    "bias2 = []\n",
    "layer3 = []\n",
    "for i in range(10):\n",
    "    layer3.append([])\n",
    "    bias1.append([])\n",
    "    bias1.append([])\n",
    "    bias2.append([])\n",
    "bias3 = []\n",
    "for i in range(trackingArray.shape[0]):\n",
    "    for k in range(200):\n",
    "        layer1[k].append(trackingArray[i][0][int(k//20)][int(k%20)])\n",
    "        layer2[k].append(trackingArray[i][2][int(k//10)][int(k%10)])\n",
    "    for k in range(10):\n",
    "        layer3[k].append(trackingArray[i][4][k][0])\n",
    "        bias2[k].append(trackingArray[i][3][k])\n",
    "        bias1[2*k].append(trackingArray[i][1][2*k])\n",
    "        bias1[2*k+1].append(trackingArray[i][1][2*k+1])\n",
    "    bias3.append(trackingArray[i][5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = np.asarray(layer1)\n",
    "layer2 = np.asarray(layer2)\n",
    "layer3 = np.asarray(layer3)\n",
    "bias1 = np.asarray(bias1)\n",
    "bias2 = np.asarray(bias2)\n",
    "bias3 = np.asarray(bias3)\n",
    "\n",
    "print(layer1.shape)\n",
    "print(layer2.shape)\n",
    "print(layer3.shape)\n",
    "print(bias1.shape)\n",
    "print(bias2.shape)\n",
    "print(bias3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    plt.plot(layer1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    plt.plot(layer2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.plot(layer3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    plt.plot(bias1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.plot(bias2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bias3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias3 = np.reshape(bias3, (bias3.shape[0]))\n",
    "bias3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allLists = []\n",
    "for i in range(200):\n",
    "    allLists.append(layer1[i])\n",
    "for i in range(200):\n",
    "    allLists.append(layer2[i])\n",
    "for i in range(10):\n",
    "    allLists.append(layer3[i])\n",
    "for i in range(20):\n",
    "    allLists.append(bias1[i])\n",
    "for i in range(10):\n",
    "    allLists.append(bias2[i])\n",
    "allLists.append(bias3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441, 1670)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allLists = np.asarray(allLists)\n",
    "allLists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n",
      "(1670,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(allLists.shape[0]):\n",
    "    allLists[i] = np.asarray(allLists[i])\n",
    "    print(allLists[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8820, 200)\n",
      "(8820,)\n"
     ]
    }
   ],
   "source": [
    "# Now comes the prediction part! Whoo Hoooo!!!\n",
    "\n",
    "# Dataset\n",
    "\n",
    "datasetX = []\n",
    "datasetY = []\n",
    "\n",
    "# Writing this part for a more complex underlying function or a lesser coomplex model\n",
    "# timeSeries length = 200\n",
    "# strides = 10\n",
    "# target Index = 600\n",
    "\n",
    "samplesPerTrainable = 20\n",
    "stride = 10\n",
    "timeSerieslength = 200\n",
    "targetIndex = 600\n",
    "\n",
    "for i in range(samplesPerTrainable):\n",
    "    for history in allLists:\n",
    "        datasetX.append(history[stride*i : stride*i + timeSerieslength])\n",
    "        datasetY.append(history[targetIndex])\n",
    "\n",
    "datasetX = np.asarray(datasetX)\n",
    "datasetY = np.asarray(datasetY)\n",
    "print(datasetX.shape)\n",
    "print(datasetY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8820, 200, 1)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetX = np.reshape(datasetX, (datasetX.shape[0], datasetX.shape[1],1))\n",
    "datasetX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 2)                 32        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "def createPredModel():\n",
    "    predictionModel = Sequential()\n",
    "    predictionModel.add(LSTM(2, input_shape = (timeSerieslength, 1), activation = 'relu'))\n",
    "    # predictionModel.add(LSTM(4, activation = 'relu'))\n",
    "    # predictionModel.add(Dense(8, activation = 'relu'))\n",
    "    predictionModel.add(Dense(4, activation = 'relu'))\n",
    "    predictionModel.add(Dense(1, activation = 'relu'))\n",
    "    predictionModel.summary()\n",
    "    return predictionModel\n",
    "predictionModel = createPredModel()\n",
    "# predictionModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionModel.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionModel.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "276/276 [==============================] - ETA: 0s - loss: 0.0487\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "276/276 [==============================] - 10s 36ms/step - loss: 0.0487\n",
      "Epoch 2/5\n",
      "275/276 [============================>.] - ETA: 0s - loss: 0.0366\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "276/276 [==============================] - 10s 35ms/step - loss: 0.0366\n",
      "Epoch 3/5\n",
      "275/276 [============================>.] - ETA: 0s - loss: 0.0365\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "276/276 [==============================] - 10s 35ms/step - loss: 0.0365\n",
      "Epoch 4/5\n",
      "275/276 [============================>.] - ETA: 0s - loss: 0.0365\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "276/276 [==============================] - 10s 34ms/step - loss: 0.0365\n",
      "Epoch 5/5\n",
      "275/276 [============================>.] - ETA: 0s - loss: 0.0364\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "276/276 [==============================] - 10s 36ms/step - loss: 0.0364\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "history = predictionModel.fit(datasetX, datasetY, epochs = num_epochs, verbose = 1, callbacks = [cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My brain is no longer working, so kindly plot the loss graph here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del predictionModel\n",
    "# del whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 2)                 32        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.27435237,  0.45819426,  0.23745227, -0.6292714 , -0.41726863,\n",
       "          0.3700328 ,  0.26488602, -0.62341654]], dtype=float32),\n",
       " array([[ 0.06680441, -0.08419874, -0.12963066, -0.7498212 ,  0.24871442,\n",
       "          0.57484424,  0.08781428, -0.0969314 ],\n",
       "        [ 0.06367179, -0.06840418,  0.73235327, -0.14363772, -0.30408862,\n",
       "          0.02356147,  0.57302654,  0.11361774]], dtype=float32),\n",
       " array([0., 0., 1., 1., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.54614687, -0.97887206,  0.14007354, -0.05383015],\n",
       "        [ 0.517184  , -0.26829004,  0.40023518,  0.4238267 ]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.45253754],\n",
       "        [ 0.43161297],\n",
       "        [-0.585993  ],\n",
       "        [-0.7919588 ]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After training on very large datasets, we have exported the weights\n",
    "impPredModel = createPredModel()\n",
    "impPredModel.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f818e0efeb8>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impPredModel.load_weights(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.42960966,  0.18915401,  0.19469452,  0.46288863,  0.3877273 ,\n",
      "         0.6729065 ,  0.66309166,  0.00203669]], dtype=float32), array([[-0.15679473, -0.27796552, -0.03266402, -0.1119389 , -0.5754204 ,\n",
      "         0.4763713 ,  0.36106753,  0.5073639 ],\n",
      "       [-0.119078  , -0.04727086, -0.11162802,  0.5945398 , -0.7004291 ,\n",
      "        -0.2671584 , -0.22107461, -0.0143703 ]], dtype=float32), array([-0.03007821,  0.25585306,  0.97006804,  1.2614328 , -0.04040473,\n",
      "        0.07297448, -0.03014812,  0.2539422 ], dtype=float32), array([[-0.04528544,  0.5408185 , -0.7875912 , -0.1999774 ],\n",
      "       [ 1.1416546 ,  0.5943705 , -0.7613721 , -0.90750957]],\n",
      "      dtype=float32), array([-0.03208489, -0.17200479,  0.        ,  0.        ], dtype=float32), array([[ 0.89263135],\n",
      "       [-0.24634705],\n",
      "       [ 0.8001125 ],\n",
      "       [-0.95446837]], dtype=float32), array([-0.03069911], dtype=float32)]\n",
      "========================================================================================================================================================================================================\n",
      "[array([[-0.42960966,  0.18915401,  0.19469452,  0.46288863,  0.3877273 ,\n",
      "         0.6729065 ,  0.66309166,  0.00203669]], dtype=float32), array([[-0.15679473, -0.27796552, -0.03266402, -0.1119389 , -0.5754204 ,\n",
      "         0.4763713 ,  0.36106753,  0.5073639 ],\n",
      "       [-0.119078  , -0.04727086, -0.11162802,  0.5945398 , -0.7004291 ,\n",
      "        -0.2671584 , -0.22107461, -0.0143703 ]], dtype=float32), array([-0.03007821,  0.25585306,  0.97006804,  1.2614328 , -0.04040473,\n",
      "        0.07297448, -0.03014812,  0.2539422 ], dtype=float32), array([[-0.04528544,  0.5408185 , -0.7875912 , -0.1999774 ],\n",
      "       [ 1.1416546 ,  0.5943705 , -0.7613721 , -0.90750957]],\n",
      "      dtype=float32), array([-0.03208489, -0.17200479,  0.        ,  0.        ], dtype=float32), array([[ 0.89263135],\n",
      "       [-0.24634705],\n",
      "       [ 0.8001125 ],\n",
      "       [-0.95446837]], dtype=float32), array([-0.03069911], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# To ensure that weights are correctly saved and imported\n",
    "print(predictionModel.get_weights())\n",
    "print(\"=\"*200)\n",
    "print(impPredModel.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 441\n",
      "Trainable params: 441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 441\n",
      "Trainable params: 441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Rapid Training:\n",
    "\n",
    "rapidModel = createExpModel()\n",
    "rapidModel.compile(optimizer = 'adam', loss= 'mse', metrics = ['accuracy'])\n",
    "\n",
    "uselessModelPartiallyTrained = createExpModel()\n",
    "uselessModelPartiallyTrained.compile(optimizer = 'adam', loss= 'mse', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 71.0097 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 71.0235 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 73.3204 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 67.5488 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.8925 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 69.0918 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.4086 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 66.4968 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.8363 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 64.8246 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 58.4702 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 60.9124 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 59.9851 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 58.4051 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 56.6262 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 54.7560 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 53.4820 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 53.1142 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 50.2780 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 50.8676 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 49.6959 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 47.9427 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48.5687 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 47.4063 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 45.9951 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 46.3588 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 43.5704 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 43.3072 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 42.6969 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 40.4765 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.8751 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 35.8494 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 37.4336 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 36.3877 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 35.2609 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 997us/step - loss: 35.0265 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 33.7030 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 32.7133 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 30.6814 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 31.7672 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 29.8225 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 29.1893 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 28.4356 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 26.9096 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 26.8647 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 25.9963 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 25.4638 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 24.1315 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 23.1108 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 22.1007 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 21.1176 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 20.5993 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 20.0685 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 19.7161 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.5786 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.4627 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.3463 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 17.0828 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.7387 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 15.7961 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.6705 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 14.3253 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 13.4917 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.6078 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.8154 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.1174 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.4066 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 11.1782 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.8640 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 9.5734 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6743 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8.7071 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.7966 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.2771 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7422 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5797 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.4547 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.2664 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7643 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.7419 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0933 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0637 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9093 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3963 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.2623 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 4.3638 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0186 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 3.4286 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8571 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0604 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.5310 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.4707 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8516 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.2082 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8087 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.7779 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.8371 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6359 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1509 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3205 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.2060 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3149 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1842 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1408 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0692 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.9084 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0019 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8668 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5951 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5784 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3744 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3518 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6112 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2791 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.2735 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4017 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2619 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2941 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1532 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1626 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 981us/step - loss: 0.4110 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3752 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2527 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3655 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2620 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1154 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2925 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2502 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1699 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2423 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1141 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1310 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 954us/step - loss: 0.4287 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2525 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1882 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2095 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2290 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1338 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2059 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1713 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2233 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2553 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1241 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1533 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4107 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5153 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3233 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1935 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1686 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2330 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1363 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2400 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 982us/step - loss: 0.1748 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 984us/step - loss: 0.2652 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1616 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 996us/step - loss: 0.0905 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2311 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1664 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2932 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2817 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3457 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2533 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2800 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1484 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2732 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3733 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1322 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.0000e+00\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# Partial Training\n",
    "\n",
    "timeSerieslength = 200\n",
    "\n",
    "trackingArray = []\n",
    "batch_size = 20\n",
    "epochs = 1 # Changed epochs from 5 to 1\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0,timeSerieslength): # Training only for 200 time steps\n",
    "        uselessModelPartiallyTrained.fit(np.asarray(inpX[i*15:i*15+batch_size]),np.asarray(targets[i*15:i*15+batch_size]))\n",
    "        trackingArray.append(np.array(uselessModelPartiallyTrained.get_weights()))\n",
    "print(len(trackingArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trackingArray = np.asarray(trackingArray)\n",
    "trackingArray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20)\n",
      "(20,)\n",
      "(20, 10)\n",
      "(10,)\n",
      "(10, 1)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(np.asarray(trackingArray[0][i]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = []\n",
    "layer2 = []\n",
    "for i in range(10*20):\n",
    "    layer1.append([])\n",
    "    layer2.append([])\n",
    "bias1 = []\n",
    "bias2 = []\n",
    "layer3 = []\n",
    "for i in range(10):\n",
    "    layer3.append([])\n",
    "    bias1.append([])\n",
    "    bias1.append([])\n",
    "    bias2.append([])\n",
    "bias3 = []\n",
    "for i in range(trackingArray.shape[0]):\n",
    "    for k in range(200):\n",
    "        layer1[k].append(trackingArray[i][0][int(k//20)][int(k%20)])\n",
    "        layer2[k].append(trackingArray[i][2][int(k//10)][int(k%10)])\n",
    "    for k in range(10):\n",
    "        layer3[k].append(trackingArray[i][4][k][0])\n",
    "        bias2[k].append(trackingArray[i][3][k])\n",
    "        bias1[2*k].append(trackingArray[i][1][2*k])\n",
    "        bias1[2*k+1].append(trackingArray[i][1][2*k+1])\n",
    "    bias3.append(trackingArray[i][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 200)\n",
      "(200, 200)\n",
      "(10, 200)\n",
      "(20, 200)\n",
      "(10, 200)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "layer1 = np.asarray(layer1)\n",
    "layer2 = np.asarray(layer2)\n",
    "layer3 = np.asarray(layer3)\n",
    "bias1 = np.asarray(bias1)\n",
    "bias2 = np.asarray(bias2)\n",
    "bias3 = np.asarray(bias3)\n",
    "bias3 = np.reshape(bias3, (bias3.shape[0]))\n",
    "\n",
    "print(layer1.shape)\n",
    "print(layer2.shape)\n",
    "print(layer3.shape)\n",
    "print(bias1.shape)\n",
    "print(bias2.shape)\n",
    "print(bias3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20)\n",
      "(20,)\n",
      "(20, 10)\n",
      "(10,)\n",
      "(10, 1)\n",
      "(1,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(np.asarray(rapidModel.get_weights()[i]).shape)\n",
    "print(np.asarray(rapidModel.get_weights()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predLayer1 = np.reshape(impPredModel(layer1), (10,20))\n",
    "predLayer1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predLayer2 = np.reshape(impPredModel(layer2), (20,10))\n",
    "predLayer2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predLayer3 = np.reshape(impPredModel(layer3), (10,1))\n",
    "predLayer3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predBias1 = np.reshape(impPredModel(bias1), (20))\n",
    "predBias1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predBias2 = np.reshape(impPredModel(bias2), (10))\n",
    "predBias2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predBias3 = np.asarray(impPredModel(np.reshape(bias3, (1,200,1))))\n",
    "predBias3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 441\n",
      "Trainable params: 441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rapidModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weights = np.asarray(rapidModel.get_layer(\"dense_43\").get_weights())\n",
    "new_weights[0] = predLayer1\n",
    "new_weights[1] = predBias1\n",
    "rapidModel.get_layer(\"dense_43\").set_weights(new_weights)\n",
    "new_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = np.asarray(rapidModel.get_layer(\"dense_44\").get_weights())\n",
    "new_weights[0] = predLayer2\n",
    "new_weights[1] = predBias2\n",
    "rapidModel.get_layer(\"dense_44\").set_weights(new_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = np.asarray(rapidModel.get_layer(\"dense_45\").get_weights())\n",
    "# print(new_weights[0].shape)\n",
    "# print(predLayer3.shape)\n",
    "new_weights[0] = predLayer3\n",
    "new_weights[1] = np.asarray([int(predBias3)])\n",
    "rapidModel.get_layer(\"dense_45\").set_weights(new_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 441\n",
      "Trainable params: 441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "uselessModel = createExpModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "biasUsed = [0.57697825, 0.28405326, 0.38593481, 0.30144476, 0.32608157, 0.54723307, 0.31920214, 0.59998487, 0.44014847, 0.26628209]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input:\n",
      "\n",
      " [[0.30146013 0.59789254 0.43531384 0.57847292 0.50906557 0.78966594\n",
      "  0.66502948 0.94082074 0.20646846 0.58602974]\n",
      " [0.06278646 0.05567005 0.03088668 0.49074021 0.88076112 0.91105441\n",
      "  0.75640297 0.32961893 0.14842908 0.13040251]\n",
      " [0.81483357 0.65957555 0.15901854 0.46766269 0.25206503 0.46461827\n",
      "  0.88336502 0.37261527 0.93598828 0.31104905]\n",
      " [0.67958042 0.86121798 0.39715713 0.72480062 0.17989683 0.84816921\n",
      "  0.26067206 0.38665169 0.70325385 0.60319081]\n",
      " [0.8461689  0.81932927 0.96977835 0.59219927 0.45830702 0.09979461\n",
      "  0.60067092 0.10401858 0.59763252 0.45444262]\n",
      " [0.35226678 0.19087731 0.08548975 0.33110277 0.56184804 0.85648227\n",
      "  0.84572195 0.39246652 0.05889016 0.23780923]\n",
      " [0.82844898 0.8413264  0.00389174 0.333549   0.19221775 0.18512274\n",
      "  0.17193269 0.45276676 0.47011416 0.90626141]\n",
      " [0.60892342 0.93169568 0.56645569 0.28422739 0.56670303 0.93118718\n",
      "  0.51364207 0.12187125 0.78566884 0.02531104]\n",
      " [0.66761766 0.22938599 0.95716841 0.05400712 0.09136112 0.99016313\n",
      "  0.08944014 0.33935514 0.30598368 0.66423548]\n",
      " [0.22544859 0.68631401 0.99539404 0.57941626 0.50190336 0.10394528\n",
      "  0.01628385 0.84868364 0.1155607  0.32666225]\n",
      " [0.33856034 0.86478785 0.21871271 0.09312027 0.51219229 0.37300107\n",
      "  0.81128793 0.16664237 0.36587433 0.50384491]\n",
      " [0.0307082  0.64657944 0.10479151 0.5646014  0.08824376 0.63050446\n",
      "  0.6986515  0.55271224 0.25248693 0.06534204]\n",
      " [0.73293477 0.40060078 0.40431784 0.36845172 0.35748204 0.14292336\n",
      "  0.70917993 0.45410457 0.72716567 0.99405661]\n",
      " [0.64155379 0.3290279  0.43297193 0.6538703  0.41619605 0.99148685\n",
      "  0.09567076 0.53507137 0.32049273 0.85028781]\n",
      " [0.06461009 0.70929563 0.28042407 0.12790991 0.93401531 0.62672547\n",
      "  0.10915874 0.27182134 0.26700951 0.50690297]]\n",
      "\n",
      "\n",
      "\n",
      "Useless Model:\n",
      "\n",
      " [[-0.05073577]\n",
      " [-0.7225418 ]\n",
      " [-0.7837732 ]\n",
      " [-0.26243034]\n",
      " [-0.5985749 ]\n",
      " [-0.50593054]\n",
      " [-0.01124576]\n",
      " [-0.6011274 ]\n",
      " [ 0.3424964 ]\n",
      " [ 0.3563161 ]\n",
      " [-0.68449306]\n",
      " [-0.42503035]\n",
      " [-0.42201808]\n",
      " [ 0.08640938]\n",
      " [-0.1851304 ]]\n",
      "\n",
      "\n",
      "\n",
      "Useless Model trained for 200 epochs:\n",
      "\n",
      " [[8.718129 ]\n",
      " [6.9004493]\n",
      " [8.59586  ]\n",
      " [8.851076 ]\n",
      " [8.753881 ]\n",
      " [7.449675 ]\n",
      " [8.130363 ]\n",
      " [8.854818 ]\n",
      " [8.005771 ]\n",
      " [7.456661 ]\n",
      " [7.919969 ]\n",
      " [6.815904 ]\n",
      " [8.4813595]\n",
      " [8.666941 ]\n",
      " [7.6949677]]\n",
      "\n",
      "\n",
      "\n",
      "Rapid trainined:\n",
      "\n",
      " [[5.343617 ]\n",
      " [4.254002 ]\n",
      " [5.127511 ]\n",
      " [5.253155 ]\n",
      " [4.8372145]\n",
      " [4.420458 ]\n",
      " [4.7542896]\n",
      " [5.13708  ]\n",
      " [4.651746 ]\n",
      " [4.59518  ]\n",
      " [4.6436415]\n",
      " [4.428107 ]\n",
      " [5.057536 ]\n",
      " [5.079246 ]\n",
      " [4.5159883]]\n",
      "\n",
      "\n",
      "\n",
      "targeted values:\n",
      "\n",
      " [8.43516086 7.71750423 8.28191873 8.47834341 8.52614015 7.61633315\n",
      " 7.92414513 8.37965589 7.87478507 7.95879171 7.80975801 7.5902682\n",
      " 8.28095282 8.2385616  7.67752674]\n"
     ]
    }
   ],
   "source": [
    "# Rapid Model's training skipped forward in time by 400 epochs\n",
    "print(\"\\nInput:\\n\\n\", inpX[150:165])\n",
    "print(\"\\n\\n\\nUseless Model:\\n\\n\",uselessModel.predict(inpX[150:165]))\n",
    "print(\"\\n\\n\\nUseless Model trained for 200 epochs:\\n\\n\",uselessModelPartiallyTrained.predict(inpX[150:165]))\n",
    "print(\"\\n\\n\\nRapid trainined:\\n\\n\",rapidModel.predict(inpX[150:165]))\n",
    "print(\"\\n\\n\\ntargeted values:\\n\\n\",calculate(inpX[150:165], biasUsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
